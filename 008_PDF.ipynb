{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Import Stuff\n",
    "import thinkplot\n",
    "import thinkstats2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The relationship between the discreet and continuous distributions is important because we sometimes need/want to transform our data between the two. \n",
    "\n",
    "One example from real life is your GPA - when you do assignments/exams, you end up with a raw percentage grade which is continuous. When this is converted to a letter scale (A, B, etc...), that letter scale is discreet - there's only a selection of possible values (b-,b,b+, etc...). This is binning. We take a continuous varaible and create a discreet variable from it. \n",
    "The other example is when your GPA is caclulated - those discreet values are assigned numbers on a 1-4 scale, then averaged together creating a new continuous value - your GPA.\n",
    "\n",
    "One place where this is commonly used is lending and credit scores. Having a credit score of 752 vs 764 makes no difference, you're placed in a category of \"excellent\", \"very good\", etc...\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\"loan_data.csv\")\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create credit-score bucket.\n",
    "df[\"grade\"] = \" \"\n",
    "scoreCol = df.columns.get_loc(\"fico\")\n",
    "gradeCol = df.columns.get_loc(\"grade\")\n",
    "\n",
    "for i in range(len(df)) :\n",
    "    if df.iloc[i,scoreCol] < 580:\n",
    "        #print(\"Less than 580-\"+str(df.iloc[i,scoreCol]))\n",
    "        df.iloc[i,gradeCol] = \"subprime\"\n",
    "    elif df.iloc[i,scoreCol] < 670:\n",
    "        #print(\"580-670-\"+str(df.iloc[i,scoreCol]))\n",
    "        df.iloc[i,gradeCol] = \"fair\"\n",
    "    elif df.iloc[i,scoreCol] < 740:\n",
    "        #print(\"670-740-\"+str(df.iloc[i,scoreCol]))\n",
    "        df.iloc[i,gradeCol] = \"good\"\n",
    "    elif df.iloc[i,scoreCol] < 800:\n",
    "        #print(\"740-800-\"+str(df.iloc[i,scoreCol]))\n",
    "        df.iloc[i,gradeCol] = \"very good\"\n",
    "    else:\n",
    "        #print(\"800+-\"+str(df.iloc[i,scoreCol]))\n",
    "        df.iloc[i,gradeCol] = \"excellent\"\n",
    "#print(str(scoreCol)+ \" \"+ str(gradeCol))\n",
    "df.head(25)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#In generic cases, we can automate this:\n",
    "bins = np.arange(580, 860, 60) #or\n",
    "bins = np.array([580, 670, 740, 800])\n",
    "indicies = np.digitize(df[\"fico\"], bins)\n",
    "groups = df.groupby(indicies)\n",
    "for i, group in groups:\n",
    "    print(i, group[\"fico\"].min(), len(group), np.exp(group[\"log.annual.inc\"]).mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Graph\n",
    "#hist2 = thinkstats2.Hist(round(df[\"fico\"], -1))\n",
    "hist2 = thinkstats2.Hist(df[\"fico\"])\n",
    "pmf2 = thinkstats2.Pmf(df[\"fico\"])\n",
    "cdf2 = thinkstats2.Cdf(df[\"fico\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create graphs\n",
    "thinkplot.PrePlot(6, rows =2, cols=3)\n",
    "thinkplot.Hist(hist2)\n",
    "thinkplot.SubPlot(2)\n",
    "thinkplot.Pmf(pmf2)\n",
    "thinkplot.SubPlot(3)\n",
    "thinkplot.Cdf(cdf2)\n",
    "thinkplot.SubPlot(4)\n",
    "thinkstats2.NormalProbabilityPlot(df[\"fico\"])\n",
    "thinkplot.SubPlot(5)\n",
    "thinkstats2.NormalProbabilityPlot(np.log(df[\"fico\"]))\n",
    "thinkplot.SubPlot(6)\n",
    "pdf = thinkstats2.EstimatedPdf(df[\"fico\"]) #See more below\n",
    "thinkplot.Pdf(pdf)\n",
    "thinkplot.Config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#We can use fancy graphs (more next chapter) to make it pretty\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5) #makes the default size larger. \n",
    "#Everything after the comma is optional. \n",
    "fig, ax = plt.subplots(1,2)\n",
    "sns.distplot(df[\"fico\"], kde_kws={\"color\":\"red\", \"label\":\"KDE\"}, hist_kws={\"label\":\"Data\"}, ax=ax[0])\n",
    "sns.distplot(df[\"fico\"], bins=bins, kde_kws={\"color\":\"red\", \"label\":\"KDE\"}, hist_kws={\"label\":\"Data\"}, ax=ax[1])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As above - the KDE produces a smoothed function, and approximates the distribution of the histogram.\n",
    "\n",
    "The smaller those bins get, the closer of an approximation. The smoothing factor accounts for 'noise' - e.g. around 750ish. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Skewness. We can visually see the skew - this one is right skewed a bit - the right side is \"stretched\" out a bit more. We can verify with caclculations..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Skew\n",
    "skw = thinkstats2.PearsonMedianSkewness(df[\"fico\"])\n",
    "print(df[\"fico\"].mean())\n",
    "print(df[\"fico\"].median())\n",
    "print(skw)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can show it a little more clearly on the graph by adding some reference lines for mean and median."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "thinkplot.PrePlot(1)\n",
    "thinkplot.Pdf(pdf)\n",
    "thinkplot.axvline(df[\"fico\"].mean(), color=\"Red\", label=\"Mean\")\n",
    "thinkplot.axvline(df[\"fico\"].median(), color=\"Green\", label=\"Median\")\n",
    "thinkplot.Config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can explore a different varaible similarly - income. \n",
    "\n",
    "We are given the income in log format. Why might that be? Can you investigate a little, and add normal income to the dataframe?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create a new column - income. This should show the regular income, not log transformed. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Challenge - try to create a function that makes the suite of 6 graphs above."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Graph - If function wasn't created. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create graphs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Try to use the data - break into groups of marginal tax rates:\n",
    "#15% on the first $49,020 of taxable income, plus\n",
    "#20.5% on the next $49,020 of taxable income (on the portion of taxable income over 49,020 up to $98,040), plus\n",
    "#26% on the next $53,939 of taxable income (on the portion of taxable income over $98,040 up to $151,978), plus\n",
    "#29% on the next $64,533 of taxable income (on the portion of taxable income over 151,978 up to $216,511), plus\n",
    "#33% of taxable income over $216,511"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create the 6 graph set of graphs for original log income"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Use the data to estimate the number of people in each tax bracket"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Use the cdf to estimate the number of people who earn Teacher Money - lowest: 59,357, highest: 101,162"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create a KDE showing the distributiion of income.\n",
    "#Try both log income, and raw income. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Challenge - Create a function that takes an income and returns a tax bill, and marginal tax rate:\n",
    "def muhTaxes(income):\n",
    "    return taxbill, margRate"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f7dd21bfe8933d21e2c58a22bc74eff6eccb2180dc6c2e2695cf2d3822934f32"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}